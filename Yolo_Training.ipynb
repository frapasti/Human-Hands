{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZepRJHEMHLKG"
   },
   "source": [
    "# #TODOs\n",
    "* Find the best architecture on a small dataset (See 3. for details)\n",
    "* Create a batch generation function in order to not fill the memory of Colab --> DONE! ;)\n",
    "* Train the best architecture on the new batch generator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xitDj09iWxz"
   },
   "source": [
    "# IMPORTS\n",
    "\n",
    "* Import all the needed libraries for the notebook\n",
    "* Mount the drive containing the datasets\n",
    "* Unzip the a small part of the dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0K0ulR4GIezQ",
    "outputId": "de7a4f00-6c6c-4833-b71c-2154f06f858d"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from natsort import natsorted\n",
    "import imutils\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import trunc\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential \n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.layers.core import Dense, Dropout, Activation \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LeakyReLU   \n",
    "from keras.regularizers import l2  \n",
    "from keras.models import Model                   \n",
    "from pathlib import Path\n",
    "\n",
    "def listdir_fullpath(d):\n",
    "    return [os.path.join(d, f) for f in os.listdir(d)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhHQ6f_lidwe"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QOJFcuch8Q8"
   },
   "source": [
    "Get all the bboxes path and all the img_paths\n",
    "Additionally read all the text files corresponding to the bounding boxes and append them to a list.\n",
    "**bboxes** contains lists of bounding boxes, one per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b59cil7YJJRM"
   },
   "outputs": [],
   "source": [
    "  #-------------#\n",
    "  #| EGO HANDS |#\n",
    "  #------------ #\n",
    "\n",
    "#Get from the unzipped dataset the list of all the paths of images and txt files\n",
    "#listdir returns unsorted so use natsorted method!\n",
    "\n",
    "#paths needed for the training set\n",
    "bboxes_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\egoHands\\egoHands\\boundingboxes'))\n",
    "img_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\egoHands\\egoHands\\frames'))\n",
    "\n",
    "assert len(bboxes_paths) == len(img_paths), f\"Number of bboxes_paths doesn't correspond with number of images!\"\n",
    "\n",
    "#Read all the text files and create a list of list of bounding boxes for the training, one list per image \n",
    "bboxes = []*len(bboxes_paths)\n",
    "for path in bboxes_paths:\n",
    "    bboxes_it = []\n",
    "    file = open(path, 'r')\n",
    "    Lines = file.readlines()\n",
    "    for line in Lines:\n",
    "        box = line.split(',')\n",
    "        if(not(int(box[0]) == 0 and int(box[1]) == 0 and int(box[2]) == 0 and int(box[3]) == 0)):\n",
    "            bboxes_it.append([int(x) for x in box])\n",
    "    bboxes.append(bboxes_it)\n",
    "\n",
    "assert(len(bboxes) == len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLdotMtBBNBv"
   },
   "outputs": [],
   "source": [
    "  #------------------------#\n",
    "  #| HEGO HORIZONTAL FLIP |#\n",
    "  #------------------------#\n",
    "\n",
    "horizontalBboxes_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\HorizontalFlip\\HorizontalFlip\\boundingboxes_horizontalflip'))\n",
    "horizontalImg_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\HorizontalFlip\\HorizontalFlip\\images_horizontalflip'))\n",
    "\n",
    "assert len(horizontalBboxes_paths) == len(horizontalImg_paths), f\"Number of bboxes_paths doesn't correspond with number of images!\"\n",
    "\n",
    "for path in horizontalBboxes_paths:\n",
    "    bboxes_it = []\n",
    "    file = open(path, 'r')\n",
    "    Lines = file.readlines()\n",
    "    for line in Lines:\n",
    "        box = line.split(',')\n",
    "        if(not(int(box[0]) == 0 and int(box[1]) == 0 and int(box[2]) == 0 and int(box[3]) == 0)):\n",
    "            bboxes_it.append([int(x) for x in box])\n",
    "    bboxes.append(bboxes_it)\n",
    "\n",
    "for path in horizontalImg_paths:\n",
    "    img_paths.append(path)\n",
    "\n",
    "assert(len(bboxes) == len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFFlMg72CQ5D"
   },
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "#| EGO VERTICAL FLIP |#\n",
    "#---------------------#\n",
    "\n",
    "verticalBboxes_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\VerticalFlip\\VerticalFlip\\boundingboxes_verticalflip'))\n",
    "verticalImg_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\VerticalFlip\\VerticalFlip\\images_verticalflip'))\n",
    "\n",
    "assert len(verticalBboxes_paths) == len(verticalImg_paths), f\"Number of bboxes_paths doesn't correspond with number of images!\"\n",
    "\n",
    "for path in verticalBboxes_paths:\n",
    "    bboxes_it = []\n",
    "    file = open(path, 'r')\n",
    "    Lines = file.readlines()\n",
    "    for line in Lines:\n",
    "        box = line.split(',')\n",
    "        if(not(int(box[0]) == 0 and int(box[1]) == 0 and int(box[2]) == 0 and int(box[3]) == 0)):\n",
    "            bboxes_it.append([int(x) for x in box])\n",
    "    bboxes.append(bboxes_it)\n",
    "\n",
    "for path in verticalImg_paths:\n",
    "    img_paths.append(path)\n",
    "\n",
    "assert(len(bboxes) == len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TCefBHR7EM1D"
   },
   "outputs": [],
   "source": [
    "#---------------#\n",
    "#| COLOR HANDS |#\n",
    "#---------------#\n",
    "\n",
    "colorBboxes_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\ColorDA\\ColorDA\\boundingboxes'))\n",
    "colorImg_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\ColorDA\\ColorDA\\frames'))\n",
    "\n",
    "assert len(colorBboxes_paths) == len(colorImg_paths), f\"Number of bboxes_paths doesn't correspond with number of images!\"\n",
    "\n",
    "for path in colorBboxes_paths:\n",
    "    bboxes_it = []\n",
    "    file = open(path, 'r')\n",
    "    Lines = file.readlines()\n",
    "    for line in Lines:\n",
    "        bboxes_it.append([int(float(x)) for x in line.split(',')])\n",
    "    bboxes.append(bboxes_it)\n",
    "\n",
    "for path in colorImg_paths:\n",
    "    img_paths.append(path)\n",
    "\n",
    "assert(len(bboxes) == len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3U1BlvluLkDf"
   },
   "outputs": [],
   "source": [
    "#------------#\n",
    "#| NO HANDS |#\n",
    "#------------#\n",
    "noHands_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\noHands\\noHands'))\n",
    "\n",
    "for path in noHands_paths:\n",
    "    img_paths.append(path)\n",
    "    bboxes.append([])\n",
    "\n",
    "assert(len(bboxes) == len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "d3Rb-_PmV-cK"
   },
   "outputs": [],
   "source": [
    "#-------------------#\n",
    "#| HANDS OVER FACE |#\n",
    "#-------------------#\n",
    "\n",
    "hofBboxes_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\handsOverFaces\\handsOverFaces\\boundingboxes'))\n",
    "hofImg_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\handsOverFaces\\handsOverFaces\\frames'))\n",
    "\n",
    "assert len(hofBboxes_paths) == len(hofImg_paths), f\"Number of bboxes_paths doesn't correspond with number of images!\"\n",
    "\n",
    "for path in hofBboxes_paths:\n",
    "    bboxes_it = []\n",
    "    file = open(path, 'r')\n",
    "    Lines = file.readlines()\n",
    "    for line in Lines:\n",
    "        bboxes_it.append([int(float(x)) for x in line.split(',')])\n",
    "    bboxes.append(bboxes_it)\n",
    "\n",
    "for path in hofImg_paths:\n",
    "    img_paths.append(path)\n",
    "\n",
    "assert(len(bboxes) == len(img_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm-okWaUtGh4"
   },
   "source": [
    "# BATCH GENERATOR\n",
    "\n",
    "This class generates batches of data from the list of bboxes and img_paths, in this way new batches are genereated every epoch and ram problems, derived from creating a single really big X and Y, are avoided.\n",
    "\n",
    "The images and boxes have to be passed converted in a specific format in order for Yolo to work:\n",
    "\n",
    "Each input image is resized to 448x448 format as required by Yolo for its input.\n",
    "Now create the grid of cells that Yolo analyzes.\n",
    "The size of the grid is 8x8 meaning that each cell will have a size of 52x52.\n",
    "\n",
    "For each bounding box calculate its center, the center will be the grid at which the bounding box is associated.\n",
    "Each grid cell has a bounding box associated with it (zero if no bounding box). The bounding box has this form [P, Ox, Oy, W, H]:\n",
    "\n",
    "\n",
    "*   P = probability that there's a hand (always 1 since we are taking ground truth boxes)\n",
    "*   Ox = X center of the bounding box w.r.t to that grid, each grid has coordinates defined by (0,0) and (1,1) being respectively the up-left and down-rigth corner of such grid\n",
    "*   Oy = Y center with same reasoning as above\n",
    "*   W = width of the bounding box w.r.t the grid size\n",
    "*   H = height of the bounding box w.r.t. the grid size\n",
    "\n",
    "So, as an example, a bounding box b = [208,208,104,104] will be associated to the cell at row = 3 and column = 3 and become b_new = [1 ,0.5 ,0.5 , 2, 2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZLfIgMvqW8NF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, path_list, bboxes_list, batch_size=32, dim=(448,448,3),\n",
    "                 divisions=7, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.path_list = path_list\n",
    "        self.S = divisions\n",
    "        self.bboxes_list = bboxes_list\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end() #triggered at beginning and end of each epoch\n",
    "        self.cell_size = dim[0]/divisions\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.path_list) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "         # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, Y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.path_list))\n",
    "        if self.shuffle == True: # For more robust data\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        Y = np.empty((self.batch_size,self.S,self.S,5))\n",
    "        \n",
    "        batch_num = 0\n",
    "        # Generate data\n",
    "        for i in indexes:\n",
    "            original_img = load_img(self.path_list[i])\n",
    "            width, height = original_img.size\n",
    "            # load the image with the required size and calculate scale factors\n",
    "            image = load_img(self.path_list[i], target_size=(448,448))\n",
    "            scale_w = 448 / width \n",
    "            scale_h = 448 / height\n",
    "            image = img_to_array(image)\n",
    "            # scale pixel values to [0, 1]\n",
    "            image = image.astype('float32')\n",
    "            image /= 255.0\n",
    "            y_img = np.zeros((self.S,self.S,5))\n",
    "            for box in self.bboxes_list[i]:\n",
    "                xleft = int(box[0] * scale_w)\n",
    "                yleft = int(box[1] * scale_h)\n",
    "                b_width = int(box[2] * scale_w)\n",
    "                b_height = int(box[3] * scale_h)\n",
    "                ox = xleft + b_width/2\n",
    "                oy = yleft + b_height/2\n",
    "                # Calculate the coordinates of the cell in the grid that contains the center \n",
    "                grid_col = trunc(ox/self.cell_size)\n",
    "                grid_row = trunc(oy/self.cell_size) \n",
    "                # Calculate the coordinates of the center of the bbox w.r.t the associated cell; (0,0) top left and (1,1) bottom right corners of the cell\n",
    "                ox_cell = (ox - (grid_col)*self.cell_size)/self.cell_size\n",
    "                oy_cell = (oy - (grid_row)*self.cell_size)/self.cell_size\n",
    "                # Calculate the width and height of the bbox in terms of cell size, a bbox of width 448/S(cell size) will have grid_width = 1\n",
    "                grid_width = b_width/self.cell_size\n",
    "                grid_heigth = b_height/self.cell_size\n",
    "                # Put the results into y; 1 represent the probability of the class\n",
    "                y = [1,ox_cell,oy_cell,grid_width,grid_heigth]\n",
    "                y_img[grid_row][grid_col] = y\n",
    "        \n",
    "            # Store sample\n",
    "            X[batch_num,] = image\n",
    "\n",
    "            # Store grid\n",
    "            Y[batch_num,] = y_img\n",
    "        \n",
    "            batch_num += 1\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ba1UYkmR7M4_"
   },
   "source": [
    "# LOSS FUNCTION\n",
    "Definition of the loss function as the one used in the paper but simpler.\n",
    "\n",
    "There are just 5 parameters for each cell [P, x, y, w, h] thus one bounding box per cell.\n",
    "\n",
    "Hence penalize the sum square root of x,y,(w)^1/2,(h)^1/2 as in the paper but just for the cells that contain a box so those with P = y_true[0] = 1.\n",
    "\n",
    "Then penalize the sum square root of P.\n",
    "\n",
    "Then penalize the sum square root of P for the cells that do not contain boxes hence with P = y_true[0] = 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zmmOcnl9MkKj"
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    # y_true (Batch size, 7, 7, 5)\n",
    "    # y_pred (Batch size, 7, 7, 5)\n",
    "\n",
    "    mse = tf.keras.losses.MeanSquaredError(reduction = \"sum\") # Define the SUM squared error loss\n",
    "    predictions = tf.reshape(y_pred,(-1,7,7,5)) # The predictions are a tensor, need some reshaping to manipulate it\n",
    "\n",
    "    exists_box = tf.expand_dims(y_true[...,0], 3) # A box exists if the first entry of the cell is equal to 1 \n",
    "\n",
    "    #------------#\n",
    "    #| BOX LOSS |#\n",
    "    #------------#\n",
    "\n",
    "    pred_box = exists_box*predictions[...,1:5] #Calculate only loss for the cells that contain a box\n",
    "    target_box = exists_box*y_true[...,1:5] #Target boxes\n",
    "\n",
    "    epsilon = tf.fill(tf.shape(pred_box[..., 2:4]), 1e-6) #Needed to avoid divergence of square root derivatives in back propagation\n",
    "\n",
    "    # width and height are penalyzed using the square root, however predictions can be negative so multiply by sign in order to obtain positive\n",
    "    # and take absoulte value in the square root \n",
    "    wh_pred = tf.math.sign(pred_box[...,3:5]) * tf.math.sqrt(tf.math.abs(pred_box[...,3:5] + epsilon))\n",
    "    wh_targ = tf.math.sqrt(target_box[...,3:5] + epsilon)\n",
    "\n",
    "    # Get also centers\n",
    "    xy_pred = pred_box[...,1:3]\n",
    "    xy_true = target_box[...,1:3]\n",
    "\n",
    "    # Concatenate the new xy and wh in order to calculate sum squared root\n",
    "    final_pred_box = tf.concat([xy_pred,wh_pred], axis = 3)\n",
    "    final_true_box = tf.concat([xy_true,wh_targ], axis = 3)\n",
    "    box_loss = mse(tf.reshape(final_pred_box, (-1, tf.shape(final_pred_box)[-1])),tf.reshape(final_true_box, (-1, tf.shape(final_true_box)[-1])))\n",
    "    \n",
    "    #---------------#\n",
    "    #| OBJECT LOSS |#\n",
    "    #---------------#\n",
    "    \n",
    "    # Take only the first entry of each box corresponding to the probability that there's an object\n",
    "    pred_obj = predictions[...,0:1]\n",
    "    true_obj = y_true[...,0:1]\n",
    "\n",
    "    #Calculate object loss as in the paper\n",
    "    object_loss = mse(tf.reshape(exists_box*pred_obj, (-1, )), tf.reshape(exists_box*true_obj, (-1, )) )\n",
    "\n",
    "    #------------------#\n",
    "    #| NO OBJECT LOSS |#\n",
    "    #------------------#\n",
    "\n",
    "    # Calculate the loss for cells that don't have objects\n",
    "    non_exists_box = 1 - exists_box\n",
    "    no_object_loss = mse(tf.reshape(non_exists_box*pred_obj, (-1, )), tf.reshape(non_exists_box*true_obj, (-1, )))\n",
    "\n",
    "    #--------------#\n",
    "    #| FINAL LOSS |#\n",
    "    #--------------#\n",
    "\n",
    "    # Penalize more the box loss and less the no object loss   \n",
    "    total_loss = 5*box_loss + object_loss + 0.5*no_object_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukGJ5PKfraU4",
    "outputId": "f69c5e26-7726-48d9-82a7-996c8465b1b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=21.84129>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the loss function works returning a numpy number\n",
    "x = tf.random.uniform((2, 7, 7, 5))\n",
    "y = tf.random.uniform((2, 7, 7, 5))\n",
    "custom_loss(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8ydV7apJrYR"
   },
   "source": [
    "# **!!READ ME!!**\n",
    "\n",
    "In order to evaluate you need to compile only one of the following three sections! In each of them there's a different model but all of them are called Yolo\n",
    "\n",
    "\n",
    "1.   Best architecture so far already trained + its skeleton\n",
    "2.   Architecture based on a Pre-trained model (Very skippable apparently (but never say never))\n",
    "3.   Custom architecture\n",
    "\n",
    "For trial change section 3, if such architecure is better than 1 go on and change 1 :) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvgoytrI1sv3"
   },
   "source": [
    "# 1. Best architecture (already trained)\n",
    "Compile to have best architecture so far:\n",
    "\n",
    "* Number of parameters : 3,100,917\n",
    "* Loss : 5.1834 (40 epochs on egoHands)\n",
    "* Accuracy : 0.0716 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zovt7OBNCsJ",
    "outputId": "e9718588-dfba-440f-b286-5ee5a4d67e9f"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "yolo = Sequential()\n",
    "lrelu = LeakyReLU(alpha=0.1)\n",
    "\n",
    "yolo.add(tf.keras.layers.Conv2D(32, (7, 7), padding=\"same\", activation = lrelu, strides = (1,1), input_shape=(448,448,3), kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", strides = (2,2), activation = lrelu, kernel_regularizer=l2(5e-4) ))\n",
    "yolo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(tf.keras.layers.Conv2D(64, (1, 1), padding=\"same\", strides = (2,2), activation = lrelu, kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(tf.keras.layers.Reshape((12544,), input_shape=(14,14,64)))\n",
    "\n",
    "\n",
    "yolo.add(Dense(245))\n",
    "\n",
    "yolo.add(tf.keras.layers.Reshape((7,7,5), input_shape=(245,)))\n",
    "\n",
    "\n",
    "yolo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfCPq6pOeVTD"
   },
   "source": [
    "If you want to skip the training just load the model weights by executing the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Btjomb5heUrN"
   },
   "outputs": [],
   "source": [
    "yolo.load_weights(r'C:\\Users\\franc\\Desktop\\Yolo_Hand\\Model\\yolo.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbcVW3-XpoWe"
   },
   "source": [
    "# 2. Custom architecture\n",
    "For trials and to hopefully replace 1. ;)\n",
    "\n",
    "To try:\n",
    "\n",
    "*   Sigmoid activation?\n",
    "*   Dropout?\n",
    "*   Add a dense layer before Dense(245)? -> There's one in the paper\n",
    "*   Batch Normalization? -> In the paper they say that with BNorm dropout is not needed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sK9I8FmmO9jb",
    "outputId": "2187bf31-0481-4aa5-f4c1-c9040c25f463"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout, Flatten, Reshape, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "yolo = Sequential()\n",
    "\n",
    "yolo.add(Conv2D(26, (3,3), padding=\"same\", strides = (1,1), input_shape=(448,448,3), kernel_regularizer=l2(5e-4)))#for large images it is better to use kernel >3\n",
    "yolo.add(BatchNormalization()) #Batch normalization needs to be executed before lrelu apparently \n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(26, (7,7), padding=\"same\", strides = (1,1), kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization()) #Batch normalization needs to be executed before lrelu apparently \n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(52, (3, 3), padding=\"same\", strides = (2,2), kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization()) \n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(104, (3,3), padding=\"same\", kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(104, (7,7), padding=\"same\", kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(Reshape((5096,), input_shape=(7, 7, 104)))\n",
    "\n",
    "yolo.add(Dense(2048))\n",
    "#2yolo.add(Dropout(0.2))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "yolo.add(Dense(245))\n",
    "#yolo.add(Dropout(0.2))\n",
    "\n",
    "yolo.add(Reshape((7,7,5), input_shape=(245,)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 448, 448, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 224, 224, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 224, 224, 32)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 64)      18496     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 224, 224, 32)      2080      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 224, 224, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 112, 112, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 112, 112, 64)      8256      \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 56, 56, 128)       32896     \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 200704)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 245)               49172725  \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 5)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,991,893\n",
      "Trainable params: 49,991,893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "length =  448\n",
    "width = 448\n",
    "input_shape = (length, width, 3)\n",
    "\n",
    "#LeakyRelu = LeakyReLU(alpha=0.1)\n",
    "\n",
    "yolo = Sequential()\n",
    "\n",
    "yolo.add(Conv2D(32, (3, 3), input_shape=input_shape, activation='relu', padding='same'))\n",
    "yolo.add(MaxPooling2D((2,2)))\n",
    "yolo.add(Dropout(0.1))\n",
    "\n",
    "yolo.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "yolo.add(Conv2D(32, (1, 1), activation='relu', padding='same'))\n",
    "yolo.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "yolo.add(MaxPooling2D((2,2)))\n",
    "yolo.add(Dropout(1e-3))\n",
    "\n",
    "yolo.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "yolo.add(Conv2D(64, (1, 1), activation='relu', padding='same'))\n",
    "yolo.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "yolo.add(MaxPooling2D((2,2)))\n",
    "yolo.add(Dropout(1e-3))\n",
    "\n",
    "yolo.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "yolo.add(Conv2D(128, (1, 1), activation='relu', padding='same'))\n",
    "yolo.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "yolo.add(MaxPooling2D((2,2)))\n",
    "yolo.add(Dropout(1e-3))\n",
    "\n",
    "yolo.add(Reshape((200704,), input_shape=(28, 28, 256)))\n",
    "\n",
    "yolo.add(Dense(245, activation=\"sigmoid\"))\n",
    "\n",
    "yolo.add(Reshape((7,7,5), input_shape=(245,)))\n",
    "\n",
    "\n",
    "print (yolo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "yolo.add(Conv2D(64, (7,7), padding=\"same\", strides = (1,1), input_shape=(448,448,3), kernel_regularizer=l2(5e-4)))#for large images it is better to use kernel >3\n",
    "yolo.add(tf.keras.layers.BatchNormalization()) #Batch normalization needs to be executed before lrelu apparently \n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(192, (3,3), padding=\"same\", strides = (1,1), kernel_regularizer=l2(5e-4)))#for large images it is better to use kernel >3\n",
    "yolo.add(tf.keras.layers.BatchNormalization()) #Batch normalization needs to be executed before lrelu apparently \n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(256, (3,3), padding=\"same\", strides = (1,1), kernel_regularizer=l2(5e-4)))#for large images it is better to use kernel >3\n",
    "yolo.add(tf.keras.layers.BatchNormalization()) #Batch normalization needs to be executed before lrelu apparently \n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(512, (3,3), padding=\"same\", strides = (1,1), kernel_regularizer=l2(5e-4)))#for large images it is better to use kernel >3\n",
    "yolo.add(tf.keras.layers.BatchNormalization()) #Batch normalization needs to be executed before lrelu apparently \n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(512, (3,3), padding=\"same\", strides = (1,1), kernel_regularizer=l2(5e-4)))#for large images it is better to use kernel >3\n",
    "yolo.add(tf.keras.layers.BatchNormalization()) #Batch normalization needs to be executed before lrelu apparently \n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(1024, (3,3), padding=\"same\", strides = (1,1), kernel_regularizer=l2(5e-4)))#for large images it is better to use kernel >3\n",
    "yolo.add(tf.keras.layers.BatchNormalization()) #Batch normalization needs to be executed before lrelu apparently \n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(1024, (3,3), padding=\"same\", strides = (1,1), kernel_regularizer=l2(5e-4)))#for large images it is better to use kernel >3\n",
    "yolo.add(tf.keras.layers.BatchNormalization()) #Batch normalization needs to be executed before lrelu apparently \n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(1024, (3,3), padding=\"same\", strides = (1,1), kernel_regularizer=l2(5e-4)))#for large images it is better to use kernel >3\n",
    "yolo.add(tf.keras.layers.BatchNormalization()) #Batch normalization needs to be executed before lrelu apparently \n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "#yolo.add(MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
    "\n",
    "yolo.add(Reshape((200704,), input_shape=(14, 14, 1024)))\n",
    "\n",
    "yolo.add(Dense(4096))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "yolo.add(Dense(245))\n",
    "\n",
    "yolo.add(Reshape((7,7,5), input_shape=(245,)))'''\n",
    "\n",
    "'''\n",
    "yolo.add(Conv2D(filters=64, kernel_size= (7, 7), strides=(1, 1), input_shape =(448, 448, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(filters=192, kernel_size= (3, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(filters=128, kernel_size= (1, 1), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=256, kernel_size= (3, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=512, kernel_size= (1, 1), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
    "\n",
    "yolo.add(Conv2D(filters=512, kernel_size= (1, 1), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=512, kernel_size= (1, 1), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=1024, kernel_size= (3, 3), strides=(2, 2), padding = 'same'))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "yolo.add(Conv2D(filters=1024, kernel_size= (3, 3), kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "yolo.add(Conv2D(filters=1024, kernel_size= (3, 3), kernel_regularizer=l2(5e-4)))\n",
    "yolo.add(BatchNormalization())\n",
    "yolo.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "yolo.add(Flatten())\n",
    "yolo.add(Dense(512))\n",
    "yolo.add(Dense(1024))\n",
    "yolo.add(Dropout(0.5))\n",
    "\n",
    "yolo.add(Dense(245))\n",
    "\n",
    "yolo.add(Reshape((7,7,5), input_shape=(245,)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2gRveHMmSsM"
   },
   "outputs": [],
   "source": [
    "#IF YOU WANT TO RESUME TRAINING FROM SAVED WEIGHTS COMPILE THIS CELL\n",
    "yolo.load_weights(r'C:\\Users\\franc\\Desktop\\Yolo_Hand\\CheckPoints\\yolo_small.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25b2ogxYp2OT"
   },
   "source": [
    "# TRAINING\n",
    "Perform the training of the model chose from 1. 2. 3. or 4. (don't need to run this cell if you loaded the already trained architecture in 1. !)\n",
    "\n",
    "For now accuracy seems to be always low, don't know why though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "7wLscl6S9bVb"
   },
   "outputs": [],
   "source": [
    "# Can also try the standard sum squared loss that penalizes everything equally\n",
    "# just use : tf.keras.losses.MeanSquaredError(reduction = \"sum\")\n",
    "\n",
    "training_generator = DataGenerator(img_paths, bboxes)\n",
    "\n",
    "checkpoint_filepath = r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\CheckPoints\\yolo_small.h5'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True)\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False, name=\"SGD\")\n",
    "yolo.compile(optimizer = 'adam',loss='binary_crossentropy', metrics = tf.keras.metrics.BinaryAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GRV-Ixw9kNO",
    "outputId": "f87dbfb4-f528-4c85-c2e3-5202adbd3532",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "217/217 [==============================] - 3268s 15s/step - loss: 0.1575 - binary_accuracy: 0.9388\n",
      "Epoch 2/7\n",
      "217/217 [==============================] - 3110s 14s/step - loss: 0.1243 - binary_accuracy: 0.9437\n",
      "Epoch 3/7\n",
      "217/217 [==============================] - 3081s 14s/step - loss: 0.1011 - binary_accuracy: 0.9416\n",
      "Epoch 4/7\n",
      "217/217 [==============================] - 3248s 15s/step - loss: 0.0430 - binary_accuracy: 0.9382\n",
      "Epoch 5/7\n",
      "217/217 [==============================] - 3159s 15s/step - loss: -0.0164 - binary_accuracy: 0.9411\n",
      "Epoch 6/7\n",
      "217/217 [==============================] - 3185s 15s/step - loss: -0.0786 - binary_accuracy: 0.9473\n",
      "Epoch 7/7\n",
      "217/217 [==============================] - 3289s 15s/step - loss: -0.1209 - binary_accuracy: 0.9521\n"
     ]
    }
   ],
   "source": [
    "history = yolo.fit(x = training_generator, epochs=7, verbose=1, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "oo83EQzYS0lS",
    "outputId": "1599acda-c629-48e8-98d7-b5896b0bc261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'binary_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-fe5dbeb16175>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0msavemat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\TrainResults\\loss_small.mat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmdic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0msavemat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\TrainResults\\accuracy_small.mat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "#Some plots for the training!\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Save the matrices for the plots\n",
    "mdic = {\"loss\": history.history['loss'] }\n",
    "savemat(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\TrainResults\\loss_small.mat', mdic)\n",
    "\n",
    "mdic = {\"accuracy\": history.history['accuracy'] }\n",
    "savemat(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\TrainResults\\accuracy_small.mat', mdic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMr5SOhQPzlp"
   },
   "source": [
    "# TESTING\n",
    "Visualize how the model works in some test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "IZWBUeUjoDRM"
   },
   "outputs": [],
   "source": [
    "#Function to transform the output of the network in the correct format\n",
    "def decode_net_out(out):\n",
    "    # IN : out [7x7x5]\n",
    "    # RETURNS : bboxes [list] of the best training boxes\n",
    "    cell_size = 448/7\n",
    "    bboxes = []\n",
    "    confidences = []\n",
    "    for i in range(0,7):\n",
    "        for j in range(0,7):\n",
    "            if out[i][j][0] > 0.5: #CONFIDENCE THRESHOLD (P of the cell)\n",
    "                bbox = np.zeros((4))\n",
    "                ox_cell = out[i][j][1]\n",
    "                oy_cell = out[i][j][2]\n",
    "                w_cell = out[i][j][3]\n",
    "                h_cell = out[i][j][4]\n",
    "                if(ox_cell != 0 and oy_cell !=0):\n",
    "                    ox = int(ox_cell*cell_size + cell_size*j)\n",
    "                    oy = int(oy_cell*cell_size + cell_size*i)\n",
    "                    w = w_cell*cell_size\n",
    "                    h = h_cell*cell_size\n",
    "                    lx = ox - w/2\n",
    "                    ly = oy - h/2\n",
    "                    bbox = [out[i][j][0],int(lx),int(ly),int(w),int(h)]\n",
    "                    bboxes.append(bbox)\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UszPiO9Dav1D",
    "outputId": "5f3d8ed8-8a1c-43dc-c544-c829638a1cb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 619ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-bd652181331c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16510\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchannels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimage_show\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m448\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m448\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for h in range(0, 5):\n",
    "    i = random.randint(0,16510)\n",
    "    image = cv2.imread(img_paths[i])\n",
    "    width,height,channels = image.shape\n",
    "    image_show = cv2.resize(image,(448,448))\n",
    "    loaded_img = load_img(img_paths[i], target_size=(448, 448))\n",
    "    scale_w = 448 / width \n",
    "    scale_h = 448 / height\n",
    "    image = img_to_array(loaded_img)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    in_net = np.expand_dims(image, axis=0) #Expand dimension because the network works with batches as input\n",
    "\n",
    "    out_net = yolo.predict(in_net)\n",
    "    out_bboxes = decode_net_out(out_net[0])\n",
    "\n",
    "    # Drawing the regions in the Image\n",
    "    for (P,x, y, w, h) in out_bboxes:\n",
    "        cv2.rectangle(image_show, (x, y), \n",
    "                        (x + w, y + h), \n",
    "                        (0, 0, 255), 2)\n",
    "        cv2.putText(image_show, 'Hand: ' + str(P), (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, w/448 + 0.2, (36,255,12), 1)\n",
    "    window_name = 'image'\n",
    "    cv2.imshow('image',image_show)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AesRHOaYZu_z"
   },
   "source": [
    "# TESTING ON EVALUATION SET!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B377suGpZ3m3",
    "outputId": "3d533e86-26a6-49c1-bac8-eff031b3840a"
   },
   "outputs": [],
   "source": [
    "test_bboxes_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\Test_Hands\\Test_Hands\\Bboxes'))\n",
    "test_img_paths = natsorted(listdir_fullpath(r'C:\\Users\\39380\\Desktop\\Yolo_DATASET\\Test_Hands\\Test_Hands\\Images'))\n",
    "\n",
    "#Read all the text files and create a list of list of bounding boxes, one list per image \n",
    "test_bboxes = []*len(test_bboxes_paths)\n",
    "for path in test_bboxes_paths:\n",
    "    bboxes_it = []\n",
    "    file = open(path, 'r')\n",
    "    Lines = file.readlines()\n",
    "    for line in Lines:\n",
    "        bboxes_it.append([int(x) for x in line.split()]) #Separated by white spaces\n",
    "    test_bboxes.append(bboxes_it)\n",
    "\n",
    "#Creation of the scaled down 448x448 version of the ground truth bboxes \n",
    "test_bboxes_scaled = []\n",
    "for i in range(0,len(test_img_paths)):\n",
    "    bboxes_it = []\n",
    "    original_img = load_img(test_img_paths[i])\n",
    "    width, height = original_img.size\n",
    "    scale_w = 448 / width \n",
    "    scale_h = 448 / height\n",
    "\n",
    "    for box in test_bboxes[i]:\n",
    "        xleft = int(box[0] * scale_w)\n",
    "        yleft = int(box[1] * scale_h)\n",
    "        b_width = int(box[2] * scale_w)\n",
    "        b_height = int(box[3] * scale_h)\n",
    "        new_bbox = [xleft,yleft,b_width,b_height]\n",
    "        bboxes_it.append(new_bbox)\n",
    "    test_bboxes_scaled.append(bboxes_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "HsejtZTgaE1t"
   },
   "outputs": [],
   "source": [
    "def calc_iou(prop_bbox, ground_truth):\n",
    "    #This function takes as input a single prop_bbox and a single ground_truth bbox and return their intersection \n",
    "    #over union\n",
    "\n",
    "    P,p_x, p_y, p_w, p_h = prop_bbox\n",
    "    g_x, g_y, g_w, g_h = ground_truth\n",
    "\n",
    "    #Non overlapping cases then IoU = 0.0:\n",
    "    #-Bottom_right smaller than top left\n",
    "    if((p_x + p_w) < g_x):\n",
    "        return 0.0\n",
    "    if((p_y + p_h) < g_y):\n",
    "        return 0.0\n",
    "    if((g_x + g_w) < p_x):\n",
    "        return 0.0\n",
    "    if((g_y + g_h) < p_y):\n",
    "        return 0.0\n",
    "\n",
    "    #Top left corner of intersection\n",
    "    x_in = max(p_x, g_x)\n",
    "    y_in = max(p_y, g_y)\n",
    "    #Bottom right corner of intersection\n",
    "    x1_in = min(p_x + p_w, g_x + g_w)\n",
    "    y1_in = min(p_y + p_h, g_y + g_h)\n",
    "    w_in = x1_in - x_in\n",
    "    h_in = y1_in - y_in\n",
    "    #Area intersection\n",
    "    area_in = w_in * h_in\n",
    "\n",
    "    #Area union\n",
    "    area_un = (p_w * p_h) + (g_w * g_h) - area_in\n",
    "\n",
    "    #Intersection Over Union\n",
    "    IoU = area_in / area_un\n",
    "\n",
    "    return IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3EtaXhrYaMM6"
   },
   "outputs": [],
   "source": [
    "def single_img_results(prop_bboxes, true_bboxes):\n",
    "    #This function returns the average IOU for a single image given its proposed bboxes and corresponding\n",
    "    #ground truth\n",
    "\n",
    "    if(len(prop_bboxes)== 0):\n",
    "        return 0.0\n",
    "\n",
    "    max_Ious = []\n",
    "\n",
    "    #For each ground truth find the prop bbox that overlaps the most\n",
    "    for true_bbox in true_bboxes:\n",
    "        Iou_results = []\n",
    "        for prop_bbox in prop_bboxes:\n",
    "            Iou_results.append(calc_iou(prop_bbox,true_bbox))\n",
    "        max_Ious.append(max(Iou_results))\n",
    "\n",
    "    #If there are more ground truth than len of max_Ious fill the list with 0s until their lenght are the same\n",
    "    if(len(true_bboxes)>len(max_Ious)):\n",
    "        app = [0.0]*len(len(true_bboxes)-len(max_Ious))\n",
    "        max_Ious.append(app)\n",
    "\n",
    "    avg_Iou = sum(max_Ious)/len(max_Ious)\n",
    "    return(avg_Iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vp6xiNpCaWL7"
   },
   "source": [
    "Now for each test image get the average IoU of the ground truth bboxes and proposed bboxes and consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Rb5xWegKaXNP",
    "outputId": "d3dcd0b6-71f9-41ff-ab49-048e035e737b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 228ms/step\n",
      "0.47927291892625046\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "0.3709459685553532\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "0.4001384973293171\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "0.3319490294358731\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "0.1451075906164141\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "0.2936651021519483\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "0.30780273415363296\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "0.5747949637255982\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "0.07111071555713777\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "0.631212239190541\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "0.20096875444821183\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "0.23692961733118717\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "0.1306904520762325\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "0.09663469011901962\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "0.06459261896136732\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "0.22766668037496693\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "0.17847030649076542\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "0.14012500416318377\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "0.22673915887004492\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "0.15842033779153655\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "0.0\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "0.49780782417743125\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "0.14822114910811077\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "0.0\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "0.12350482397201934\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "0.09479287202036565\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "0.3089993687817488\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "0.08318356867779204\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "0.1270730614074406\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "0.23641834743005855\n",
      "TOTAL AVG IOU = 0.22957461319478498\n"
     ]
    }
   ],
   "source": [
    "avg_Ious = []\n",
    "for i in range(0, len(test_img_paths)):\n",
    "    loaded_img = load_img(test_img_paths[i], target_size=(448, 448))\n",
    "    image = img_to_array(loaded_img)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    in_net = np.expand_dims(image, axis=0) #Expand dimension because the network works with batches as input\n",
    "\n",
    "    out_net = yolo.predict(in_net)\n",
    "    prop_bboxes = decode_net_out(out_net[0])\n",
    "\n",
    "    avg_Iou = single_img_results(prop_bboxes, test_bboxes_scaled[i])\n",
    "    print(avg_Iou)\n",
    "    avg_Ious.append(avg_Iou)\n",
    "\n",
    "    #DRAW THE IMAGE\n",
    "    image = cv2.imread(test_img_paths[i])\n",
    "    width,height,channels = image.shape\n",
    "    scale_w = 448/width\n",
    "    scale_h = 448/height\n",
    "    image_show = cv2.resize(image,(448,448))\n",
    "    # Drawing the regions in the Image\n",
    "    for (P,x, y, w, h) in prop_bboxes:\n",
    "        cv2.rectangle(image_show, (x, y), \n",
    "                      (x + w, y + h), \n",
    "                       (0, 0, 255), 2)\n",
    "        cv2.putText(image_show, 'Hand: ' + str(P), (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, w/448 + 0.2, (36,255,12), 1)\n",
    "    for (x, y, w, h) in test_bboxes_scaled[i]:\n",
    "        cv2.rectangle(image_show, (x, y), \n",
    "                      (x + w, y + h), \n",
    "                       (0, 255, 0), 2)\n",
    "    window_name = 'image'\n",
    "    cv2.imshow('image',image_show)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "print(\"TOTAL AVG IOU = \" + str(sum(avg_Ious)/len(avg_Ious)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTiUhf5aQRtr"
   },
   "source": [
    "# IF YOU FOUND A BETTER MODEL\n",
    "Run this cell after creating a new google drive folder to save the new best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chp-w23-mlqe"
   },
   "outputs": [],
   "source": [
    "yolo.save_weights('/content/drive/MyDrive/YOLO_BEST/yolo_best.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "2QiQc0GANMr9"
   ],
   "name": "Copia di Yolo_training.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
