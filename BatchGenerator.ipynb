{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BatchGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3jzL/f+z47PL45L/dnxz2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frapasti/Human-Hands/blob/main/BatchGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install natsort\n",
        "import os\n",
        "from natsort import natsorted\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import cv2\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from math import trunc\n",
        "\n",
        "from keras.models import Sequential \n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation \n",
        "from keras.utils import np_utils\n",
        "from keras.layers import LeakyReLU   \n",
        "from keras.regularizers import l2  \n",
        "from tensorflow import keras\n",
        "from keras.models import Model                   \n",
        "\n",
        "def listdir_fullpath(d):\n",
        "    return [os.path.join(d, f) for f in os.listdir(d)]\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!unzip drive/My\\ Drive/DataSet/egoHands.zip"
      ],
      "metadata": {
        "id": "dP1krVZtTeFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get from the unzipped dataset the list of all the paths of images and txt files\n",
        "#listdir returns unsorted so use natsorted method!\n",
        "bboxes_paths = natsorted(listdir_fullpath('/content/egoHands/boundingboxes'))\n",
        "img_paths = natsorted(listdir_fullpath('/content/egoHands/frames'))\n",
        "\n",
        "assert len(bboxes_paths) == len(img_paths), f\"Number of bboxes_paths doesn't correspond with number of images!\"\n",
        "\n",
        "#Read all the text files and create a list of list of bounding boxes, one list per image \n",
        "bboxes = []*len(bboxes_paths)\n",
        "for path in bboxes_paths:\n",
        "  bboxes_it = []\n",
        "  file = open(path, 'r')\n",
        "  Lines = file.readlines()\n",
        "  for line in Lines:\n",
        "    bboxes_it.append([int(x) for x in line.split(',')])\n",
        "  bboxes.append(bboxes_it)"
      ],
      "metadata": {
        "id": "cg4dkW-jUGOi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qRSPsKuSKeUs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, path_list, bboxes_list, batch_size=25, dim=(448,448,3),\n",
        "                 divisions=7, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.path_list = path_list\n",
        "        self.S = divisions\n",
        "        self.bboxes_list = bboxes_list\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end() #triggered at beginning and end of each epoch\n",
        "        self.cell_size = dim[0]/divisions\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.path_list) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      \n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Generate data\n",
        "        X, Y = self.__data_generation(indexes)\n",
        "\n",
        "        return X, Y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.path_list))\n",
        "        if self.shuffle == True: # For more robust data\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, indexes):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim))\n",
        "        Y = np.empty((self.batch_size,self.S,self.S,5))\n",
        "\n",
        "        batch_num = 0\n",
        "        # Generate data\n",
        "        for i in indexes:\n",
        "          original_img = load_img(self.path_list[i])\n",
        "          width, height = original_img.size\n",
        "          # load the image with the required size and calculate scale factors\n",
        "          image = load_img(self.path_list[i], target_size=(448, 448))\n",
        "          scale_w = 448 / width \n",
        "          scale_h = 448 / height\n",
        "          image = img_to_array(image)\n",
        "          # scale pixel values to [0, 1]\n",
        "          image = image.astype('float32')\n",
        "          image /= 255.0\n",
        "          y_img = np.zeros((self.S,self.S,5))\n",
        "          for box in self.bboxes_list[i]:\n",
        "            xleft = int(box[0] * scale_w)\n",
        "            yleft = int(box[1] * scale_h)\n",
        "            b_width = int(box[2] * scale_w)\n",
        "            b_height = int(box[3] * scale_h)\n",
        "            \n",
        "            ox = xleft + b_width/2\n",
        "            oy = yleft + b_height/2\n",
        "            # Calculate the coordinates of the cell in the grid that contains the center \n",
        "            grid_col = trunc(ox/self.cell_size)\n",
        "            grid_row = trunc(oy/self.cell_size) \n",
        "            # Calculate the coordinates of the center of the bbox w.r.t the associated cell; (0,0) top left and (1,1) bottom right corners of the cell\n",
        "            ox_cell = (ox - (grid_col)*self.cell_size)/self.cell_size\n",
        "            oy_cell = (oy - (grid_row)*self.cell_size)/self.cell_size\n",
        "            # Calculate the width and height of the bbox in terms of cell size, a bbox of width 448/S(cell size) will have grid_width = 1\n",
        "            grid_width = b_width/self.cell_size\n",
        "            grid_heigth = b_height/self.cell_size\n",
        "            # Put the results into y; 1 represent the probability of the class\n",
        "            y = [1,ox_cell,oy_cell,grid_width,grid_heigth]\n",
        "            y_img[grid_row][grid_col] = y\n",
        "\n",
        "          # Store sample\n",
        "          X[batch_num,] = image\n",
        "\n",
        "          # Store grid\n",
        "          Y[batch_num,] = y_img\n",
        "        \n",
        "          batch_num += 1\n",
        "\n",
        "        return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "  \n",
        "  # y_true (Batch size, 7, 7, 5)\n",
        "  # y_pred (Batch size, 7, 7, 5)\n",
        "\n",
        "  mse = tf.keras.losses.MeanSquaredError(reduction = \"sum\") # Define the SUM squared error loss\n",
        "  predictions = tf.reshape(y_pred,(-1,7,7,5)) # The predictions are a tensor, need some reshaping to manipulate it\n",
        "\n",
        "  exists_box = tf.expand_dims(y_true[...,0], 3) # A box exists if the first entry of the cell is equal to 1 \n",
        "\n",
        "  #------------#\n",
        "  #| BOX LOSS |#\n",
        "  #------------#\n",
        "\n",
        "  pred_box = exists_box*predictions[...,1:5] #Calculate only loss for the cells that contain a box\n",
        "  target_box = exists_box*y_true[...,1:5] #Target boxes\n",
        "\n",
        "  epsilon = tf.fill(tf.shape(pred_box[..., 2:4]), 1e-6) #Needed to avoid divergence of square root derivatives in back propagation\n",
        "\n",
        "  # width and height are penalyzed using the square root, however predictions can be negative so multiply by sign in order to obtain positive\n",
        "  # and take absoulte value in the square root \n",
        "  wh_pred = tf.math.sign(pred_box[...,3:5]) * tf.math.sqrt(tf.math.abs(pred_box[...,3:5] + epsilon))\n",
        "  wh_targ = tf.math.sqrt(target_box[...,3:5] + epsilon)\n",
        "\n",
        "  # Get also centers\n",
        "  xy_pred = pred_box[...,1:3]\n",
        "  xy_true = target_box[...,1:3]\n",
        "\n",
        "  # Concatenate the new xy and wh in order to calculate sum squared root\n",
        "  final_pred_box = tf.concat([xy_pred,wh_pred], axis = 3)\n",
        "  final_true_box = tf.concat([xy_true,wh_targ], axis = 3)\n",
        "  box_loss = mse(tf.reshape(final_pred_box, (-1, tf.shape(final_pred_box)[-1])),tf.reshape(final_true_box, (-1, tf.shape(final_true_box)[-1])))\n",
        "  \n",
        "\n",
        "  #---------------#\n",
        "  #| OBJECT LOSS |#\n",
        "  #---------------#\n",
        "  \n",
        "  # Take only the first entry of each box corresponding to the probability that there's an object\n",
        "  pred_obj = predictions[...,0:1]\n",
        "  true_obj = y_true[...,0:1]\n",
        "\n",
        "  #Calculate object loss as in the paper\n",
        "  object_loss = mse(tf.reshape(exists_box*pred_obj, (-1, )), tf.reshape(exists_box*true_obj, (-1, )) )\n",
        "\n",
        "  #------------------#\n",
        "  #| NO OBJECT LOSS |#\n",
        "  #------------------#\n",
        "\n",
        "  # Calculate the loss for cells that don't have objects\n",
        "  non_exists_box = 1 - exists_box\n",
        "  no_object_loss = mse(tf.reshape(non_exists_box*pred_obj, (-1, )), tf.reshape(non_exists_box*true_obj, (-1, )))\n",
        "\n",
        "  #--------------#\n",
        "  #| FINAL LOSS |#\n",
        "  #--------------#\n",
        "\n",
        "  # Penalize more the box loss and less the no object loss   \n",
        "  total_loss = 5*box_loss + object_loss + 0.5*no_object_loss\n",
        "  \n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "Amuq8K-rUOUb"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "yolo = Sequential()\n",
        "lrelu = LeakyReLU(alpha=0.1)\n",
        "\n",
        "yolo.add(tf.keras.layers.Conv2D(32, (7, 7), padding=\"same\", activation = lrelu, strides = (1,1), input_shape=(448,448,3), kernel_regularizer=l2(5e-4)))\n",
        "yolo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
        "\n",
        "yolo.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", strides = (2,2), activation = lrelu, kernel_regularizer=l2(5e-4) ))\n",
        "yolo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
        "\n",
        "yolo.add(tf.keras.layers.Conv2D(64, (1, 1), padding=\"same\", strides = (2,2), activation = lrelu, kernel_regularizer=l2(5e-4)))\n",
        "yolo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides = (2,2), padding = 'same'))\n",
        "\n",
        "yolo.add(tf.keras.layers.Reshape((12544,), input_shape=(14,14,64)))\n",
        "\n",
        "\n",
        "yolo.add(Dense(245))\n",
        "\n",
        "yolo.add(tf.keras.layers.Reshape((7,7,5), input_shape=(245,)))\n",
        "\n",
        "\n",
        "yolo.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBJLE21zUV5Z",
        "outputId": "071c5f33-aad0-4daf-f651-ebaf90f97f2b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 448, 448, 32)      4736      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 224, 224, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 64)        4160      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 245)               3073525   \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 7, 7, 5)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,100,917\n",
            "Trainable params: 3,100,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_generator = DataGenerator(img_paths, bboxes)"
      ],
      "metadata": {
        "id": "PS5REt5bUvnu"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also try the standard sum squared loss that penalizes everything equally\n",
        "# just use : tf.keras.losses.MeanSquaredError(reduction = \"sum\")\n",
        "checkpoint_filepath = '/content/drive/MyDrive/CheckPoints'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True)\n",
        "yolo.compile(loss=custom_loss, optimizer='adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "eeZfjEQEUbzB"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo.fit(x = training_generator, epochs=10, verbose=1, callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI7NkYayX-fm",
        "outputId": "86e73e0d-9ce6-4343-d151-2613856c8563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 45/191 [======>.......................] - ETA: 18:56 - loss: 75.1115 - accuracy: 0.0842"
          ]
        }
      ]
    }
  ]
}